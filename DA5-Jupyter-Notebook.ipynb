{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 222](https://github.com/GonzagaCPSC222) Intro to Data Science\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "## DA5 Jupyter Notebook (100 pts)\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Write Markdown and code cells in Jupyter Notebook\n",
    "* Type set equations using Latex\n",
    "* Tell a data science story\n",
    "* Parse JSON data\n",
    " \n",
    "## Prerequisites\n",
    "Before starting this programming assignment, participants should be able to:\n",
    "* Use pandas for data analysis\n",
    "* Use matplotlib to visualize data\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this assignment is based upon information in the following sources:\n",
    "* [The COVID Tracking Project Data API](https://covidtracking.com/data/api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Classroom Setup\n",
    "For this assignment, you will use GitHub Classroom to create a private code repositories to track code changes and submit your assignment. Open this DA5 link to accept the assignment and create a private repository for your assignment in Github classroom: https://classroom.github.com/a/eMsFWSLZ \n",
    "\n",
    "Your repo, for example, will be named GonzagaCPSC222/da5-yourusername (where yourusername is your Github username). I highly recommend committing/pushing regularly so your work is always backed up. We will grade your most recent commit, even if that commit is after the due date (your work will be marked late if this is the case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming (40 pts)\n",
    "For this assignment, we are going to use a Jupyter Notebook, called WACovidEDA.ipynb, to tell a story about exploratory data analysis (EDA) of a JSON dataset. Your source code, explanations/log, and charts will be combined in a Jupyter Notebook with well-organized, interleaved code cells and markdown cells. Here are general requirements that your Notebook should conform to:\n",
    "* Your EDA story should be logically divided into different section levels, appropriately labeled using markdown headers, and contain well-written commentary describing the code, results, and insights you come up with\n",
    "* Each chart that you generate must be generated inline in the Notebook and include a figure title and labels on the x and y axes where appropriate\n",
    "* Each formula that you use in your code must be typeset using Latex and described in markdown (this includes formulas used for stats, even if those stats are implemented in a pandas function/method you call)\n",
    "    \n",
    "### Dataset\n",
    "The dataset we are going to use is going to be downloaded by your code! We are going to fetch the daily COVID-19 data for Washington state from [covidtracking.com](https://covidtracking.com/data/api). The specific URL we are going to use to download the data is https://api.covidtracking.com/v1/states/wa/daily.json You can/should open this url now and take a look at the data. It is in JSON format :) \n",
    "\n",
    "Here is starter code that fetches this JSON data from the above URL and writes the data to a file called \"dailyWA.json\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "\n",
    "# data source \n",
    "# https://covidtracking.com/data/api\n",
    "# historic value for a single state\n",
    "# note: data is also available as a CSV output \n",
    "# at https://covidtracking.com/data/download click Washington \n",
    "# to download the \"washington-history.csv\"\n",
    "\n",
    "# URL to fetch data from \n",
    "url = \"https://api.covidtracking.com/v1/states/wa/daily.json\"\n",
    "# download raw JSON object from the URL\n",
    "data = urllib.request.urlopen(url).read().decode()\n",
    "# write JSON object to an output file\n",
    "outfile = open(\"dailyWA.json\", \"w\")\n",
    "outfile.write(data)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you run this code, you will have dailyWA.json on your local machine and can begin the following data storytelling execises.\n",
    "\n",
    "### Python Data Storytelling Exercises\n",
    "1. Convert dailyWA.json to dailyWA.csv (e.g. convert the JSON data to CSV data and write out the resulting CSV file)\n",
    "1. Load the dailyWA.csv data into a pandas DataFrame object. Add a new column to the DataFrame called \"month\" that simply stores the month for each row (e.g. 1, 2, 3,..., 10 or \"Jan\", \"Feb\", \"March\",..., \"Oct\")\n",
    "1. Display the total number of new positive cases for each month. Then display the mean and standard deviation across the months. \n",
    "1. Create two charts. The first chart is of the accumulated positive cases over time and second chart is of the accumulated negative cases over time.\n",
    "\n",
    "Note: the code for the above exercises does not need to be modular (e.g. you don't need to write functions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus (7 pts)\n",
    "(4 pts) Create a third chart that plots both the accumulated positive and negative cases on the same Matplotlib figure. Your chart should have two Y-axes so you can see the trend of each line clearly (otherwise the negative case numbers are so large the scale of a single Y-axis washes out the trend of the positive case numbers). Include a legend for each line.\n",
    "\n",
    "(3 pts) Modify the X-axis labels so they show the month. \n",
    "\n",
    "Here is the bonus plot in action (note depending on when you download the JSON data, your chart will likely contain additional days of data):\n",
    "<img src=\"https://github.com/GonzagaCPSC222/DAs/raw/master/figures/wa_covid_bonus_chart.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Proposal (40 pts)\n",
    "### Overview\n",
    "For the \"Quantified Self\" project, you are going to create and analyze your own dataset by collecting longitudinal data (data collected over time) on yourself. Previous DAs have included incremental tasks related to exploring what data on yourself you want to collect and some preliminary analyses of this data. Now, you are going to decide on the dataset, analyses, and hypotheses.\n",
    "\n",
    "Your \"Quantified Self\" dataset can be any dataset that includes your own data, so long as it conforms to the following requirements:\n",
    "1. It spans at least two months of a recent data collection period\n",
    "1. It has at least 5 attributes of different measurement scales, including a \"class\" attribute to be used for classification (e.g. the data is labeled and can be used with supervised machine learning algorithms)\n",
    "1. It contains at least two tables that can be joined (e.g. each table is from a different data source. As an example, consider my Fitbit CSV file and the days of the week CSV file from DA3). \n",
    "\n",
    "Include your dataset files in your Github repo.\n",
    "\n",
    "### Propose the Project\n",
    "In a Jupyter Notebook named ProjectProposal.ipynb, formally write up your proposed project. Your proposal should be a narrative that is written in a data-storytelling format and is grammatically-correct. If you have preliminary Python code from previous DAs that is relevant for the proposal, please interleave it via code cells in your Jupyter Notebook.\n",
    "\n",
    "Your proposal should have the following headers and content:\n",
    "1. Title of your project (heading level 1)\n",
    "1. Introduction (heading level 2)\n",
    "    1. Domain introduction (heading level 3)\n",
    "        1. Introduce the domain of your project (e.g. the fitness domain, the music domain, the medical domain, etc.)\n",
    "        1. Personally, why is this domain important to you\n",
    "        1. What are you researching in this domain\n",
    "    1. Hypotheses (heading level 3)\n",
    "        1. What are your hypotheses about insights/results in this domain\n",
    "        1. What are potential impacts of the results\n",
    "        1. Who are [stakeholders](https://www.projectmanager.com/blog/what-is-a-stakeholder) interested in your results\n",
    "1. Data Analysis (heading level 2)\n",
    "    1. Dataset description (heading level 3)\n",
    "        1. What tables are included in the dataset and how is the data in each table collected\n",
    "        1. What is its format (e.g. CSV files, JSON files, a mix of the two, etc.)\n",
    "        1. Include a brief description of the attributes\n",
    "    1. Data preparation (heading level 3)\n",
    "        1. What cleaning of the dataset is required (e.g.. are there missing values and how do you plan to handle the missing values)\n",
    "        1. How are you going to merge the tables\n",
    "        1. What are anticipated challenges with data preparation\n",
    "    1. Exploratory data analysis (heading level 3)\n",
    "        1. What data aggregation techniques are you going to apply\n",
    "        1. What visualizations will informatively present the attributes and relationships\n",
    "        1. What statistical hypothesis tests are you going to compute\n",
    "    1. Classification (heading level 3)\n",
    "        1. What attribute will you use as class information (i.e., what attribute or attributes will you try to predict)\n",
    "        1. What are your hypotheses about the predictions\n",
    "        1. What are anticipated challenges with classification\n",
    "        \n",
    "Note: looking forward, the final project report will include variations of the above sections (with code/results), as well as sections titled \"Discussion\" and \"Conclusion\".\n",
    "\n",
    "### Project Timeline\n",
    "About three weeks after your project proposal is approved, we will have a \"mid-project\" demo due. For this, you will demo a Jupyter Notebook with results for \"Data preparation\" and \"Exploratory data analysis\". You will also demo preliminary work/results on your classification approach.\n",
    "\n",
    "The final project deliverables include a presentation/demo on Thursday, December 13th from 1-3pm, as well as a final report that will be due that night at 11:59pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ethics (20 pts)\n",
    "Watch Netflix's documentary, [\"The Social Dilemma\"](https://www.netflix.com/title/81254224). While I encourage you to watch the whole documentary (1 hour and 34 mins), I'm only assigning the following ~45 minute chunk: 5:45 (title page) to 49:01. \n",
    "\n",
    "Note: If you do not have access to Netflix, you can read the transcript of the documentary [here](https://scrapsfromtheloft.com/2020/10/03/the-social-dilemma-movie-transcript/). Read from \"Aza does welcoming remarks. We play the video.\" to \"Because they’re controlling, you know, the information that we see, they’re controlling us more than we’re controlling them.\" (this part of the transcript corresponds with the assigned timestamps above). Use the web browser search feature (e.g. ctrl + F or cmd + F) to search for the start of the reading.\n",
    "\n",
    "In a Jupyter Notebook called Ethics.ipynb, provide your reflection on the following discussion points:\n",
    "1. Toward the beginning of the documentary, viewers are presented with the idea that social media sells our attention to advertisers to make their profits. The quote that best summarizes this business model is, \"If you’re not paying for the product, then you are the product.\" How do you feel about selling your attention to use the products for free? Are there short and long term effects that we can/cannot foresee?\n",
    "1. Tristan Harris states, \"On the other side of the screen, it’s almost as if they had this avatar voodoo doll-like model of us. All of the things we’ve ever done, all the clicks we’ve ever made, all the videos we’ve watched, all the likes, that all gets brought back into building a more and more accurate model. The model, once you have it, you can predict the kinds of things that person does.\" He then states that tech companies have three main goals: engagement (drive up your usage), growth (keep you coming back and inviting friends), and advertising (making as much money as possible from advertising). Are there ethical lines that companies should not cross in order to achieve these three goals? Do you feel that the \"avatar voodoo doll-like model of us\" crosses these lines? Why or why not?\n",
    "1. How do you feel about persuasive technology (e.g. programming of the \"the positive intermittent reinforcement\", AKA the slot machine)? As humans, are we able to differentiate between our original thoughts and ones that are \"planted\" as an unconcious by persuasive technology?\n",
    "1. What else struck you about this documentary?\n",
    "\n",
    "This write-up should be written using full sentences and should be grammaticallly correct. Proof read your writing before you submit it!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Assignments\n",
    "1. Use Github classroom to submit your assignment via a Github repo. See the \"Github Classroom Setup\" section at the beginning of this document for details on how to do this. You must commit your solution by the due date and time.\n",
    "1. Your repo should contain only your .ipynb file(s) and your .csv or .json file(s). Double check that this is the case by cloning (or downloading a zip) your submission repo and running your code from Jupyter Lab like we will when we grade your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidelines\n",
    "This assignment is worth 100 points + 7 points bonus. Your assignment will be evaluated based on a successful execution in Jupyter Lab (using the Anaconda Python Distribution v3.8) and adherence to the program requirements. We will grade according to the following criteria:\n",
    "* 5 pts for converting the JSON file to a CSV file\n",
    "* 10 pts for correct monthly stats\n",
    "* 10 pts for correct accumulated cases charts\n",
    "* 5 pts for data storytelling using Markdown cells\n",
    "* 5 pts for typesetting stats formulas using Latex\n",
    "* 5 pts for adherence to course [coding standard](https://nbviewer.jupyter.org/github/GonzagaCPSC222/DAs/blob/master/Coding%20Standard.ipynb)\n",
    "* 40 pts for quality, clarity, and creativity in the project proposal, as well as coverage of the required headers and content\n",
    "* 20 pts for quality, clarity, and creativity in the data ethics write-up"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
